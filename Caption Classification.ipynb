{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption classification ##\n",
    "\n",
    "This model can be used to train and classify on any differentiation texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper_2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('/home/ubuntu/Thesis/Consolidated Data/*.txt')\n",
    "sentences = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file) as texts:\n",
    "        content = texts.readlines()\n",
    "        for text in content: \n",
    "            sentences.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's how we roll.\n",
      "\n",
      "<class 'str'>\n",
      "9230544\n",
      "That's how we r\n"
     ]
    }
   ],
   "source": [
    "texts = ''.join(sentences)\n",
    "print(*sentences[:1],sep='\\n')\n",
    "print(type(texts))\n",
    "print(len(texts))\n",
    "print(texts[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas = pd.DataFrame({'sentences':sentences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's how we roll.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It’s true! He calls me His co-pilot.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got it at a garage sale.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You wanted a bigger halo, yes it is razor shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You had me at Halo.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0                              That's how we roll.\\n\n",
       "1             It’s true! He calls me His co-pilot.\\n\n",
       "2                       I got it at a garage sale.\\n\n",
       "3  You wanted a bigger halo, yes it is razor shar...\n",
       "4                              You had me at Halo.\\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def load_clean_descriptions(filename):\n",
    "    doc = load_doc(filename)\n",
    "    descriptions = []\n",
    "    for line in doc.split():\n",
    "#         tokens = line.split()\n",
    "        image_desc = line\n",
    "        descriptions.append(image_desc)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_descriptions = load_clean_descriptions('/home/ubuntu/Thesis/8k_descriptions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_out = pd.read_table('/home/ubuntu/Thesis/Flickr8k.token.txt', sep='\\t', names=('A', 'B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#0</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#1</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#2</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#3</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#4</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             A  \\\n",
       "0  1000268201_693b08cb0e.jpg#0   \n",
       "1  1000268201_693b08cb0e.jpg#1   \n",
       "2  1000268201_693b08cb0e.jpg#2   \n",
       "3  1000268201_693b08cb0e.jpg#3   \n",
       "4  1000268201_693b08cb0e.jpg#4   \n",
       "\n",
       "                                                   B  \n",
       "0  A child in a pink dress is climbing up a set o...  \n",
       "1              A girl going into a wooden building .  \n",
       "2   A little girl climbing into a wooden playhouse .  \n",
       "3  A little girl climbing the stairs to her playh...  \n",
       "4  A little girl in a pink dress going into a woo...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_2 = check_out.drop(columns='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   B\n",
       "0  A child in a pink dress is climbing up a set o...\n",
       "1              A girl going into a wooden building .\n",
       "2   A little girl climbing into a wooden playhouse .\n",
       "3  A little girl climbing the stairs to her playh...\n",
       "4  A little girl in a pink dress going into a woo..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_2['value'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas['value'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164995, 40460)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pandas), len(pandas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's how we roll.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It’s true! He calls me His co-pilot.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got it at a garage sale.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You wanted a bigger halo, yes it is razor shar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You had me at Halo.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  value\n",
       "0                              That's how we roll.\\n      1\n",
       "1             It’s true! He calls me His co-pilot.\\n      1\n",
       "2                       I got it at a garage sale.\\n      1\n",
       "3  You wanted a bigger halo, yes it is razor shar...      1\n",
       "4                              You had me at Halo.\\n      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   B  value\n",
       "0  A child in a pink dress is climbing up a set o...      0\n",
       "1              A girl going into a wooden building .      0\n",
       "2   A little girl climbing into a wooden playhouse .      0\n",
       "3  A little girl climbing the stairs to her playh...      0\n",
       "4  A little girl in a pink dress going into a woo...      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_2 = pandas_2.rename(index=str, columns={\"B\" : \"sentences\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_entire = pd.concat([pandas[:40460], pandas_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's how we roll.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It’s true! He calls me His co-pilot.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got it at a garage sale.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You wanted a bigger halo, yes it is razor shar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You had me at Halo.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  value\n",
       "0                              That's how we roll.\\n      1\n",
       "1             It’s true! He calls me His co-pilot.\\n      1\n",
       "2                       I got it at a garage sale.\\n      1\n",
       "3  You wanted a bigger halo, yes it is razor shar...      1\n",
       "4                              You had me at Halo.\\n      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_entire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80920"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pandas_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "re_tok = re.compile('([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_descriptions(descriptions):\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    for _, desc_list in descriptions.items():\n",
    "        for i in range(len(desc_list)):\n",
    "            desc = desc_list[i]\n",
    "            desc = desc.split()\n",
    "            desc = [word.lower() for word in desc]\n",
    "            desc = [re_punc.sub('', w) for w in desc]\n",
    "            desc = [word for word in desc if len(word)>1]\n",
    "            desc = [word for word in desc if word.isalpha()]\n",
    "            desc_list[i] =  ' '.join(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_entire['sentences'] = pandas_entire['sentences'].str.replace('\\W+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That s how we roll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It s true He calls me His co pilot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got it at a garage sale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You wanted a bigger halo yes it is razor sharp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You had me at Halo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentences  value\n",
       "0                              That s how we roll       1\n",
       "1              It s true He calls me His co pilot       1\n",
       "2                       I got it at a garage sale       1\n",
       "3  You wanted a bigger halo yes it is razor sharp       1\n",
       "4                              You had me at Halo       1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_entire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "toktok = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = [toktok.tokenize(sent) for sent in pandas_entire['sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenized_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80920"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pandas_entire['sentences']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-02 19:35:31,374 : INFO : collecting all words and their counts\n",
      "2018-04-02 19:35:31,375 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-02 19:35:31,403 : INFO : PROGRESS: at sentence #10000, processed 97471 words, keeping 9349 word types\n",
      "2018-04-02 19:35:31,435 : INFO : PROGRESS: at sentence #20000, processed 202854 words, keeping 15345 word types\n",
      "2018-04-02 19:35:31,469 : INFO : PROGRESS: at sentence #30000, processed 313253 words, keeping 19478 word types\n",
      "2018-04-02 19:35:31,503 : INFO : PROGRESS: at sentence #40000, processed 422801 words, keeping 22930 word types\n",
      "2018-04-02 19:35:31,533 : INFO : PROGRESS: at sentence #50000, processed 531751 words, keeping 24923 word types\n",
      "2018-04-02 19:35:31,563 : INFO : PROGRESS: at sentence #60000, processed 639798 words, keeping 25946 word types\n",
      "2018-04-02 19:35:31,593 : INFO : PROGRESS: at sentence #70000, processed 746558 words, keeping 26867 word types\n",
      "2018-04-02 19:35:31,623 : INFO : PROGRESS: at sentence #80000, processed 854968 words, keeping 27526 word types\n",
      "2018-04-02 19:35:31,627 : INFO : collected 27603 word types from a corpus of 865142 raw words and 80920 sentences\n",
      "2018-04-02 19:35:31,627 : INFO : Loading a fresh vocabulary\n",
      "2018-04-02 19:35:31,815 : INFO : min_count=1 retains 27603 unique words (100% of original 27603, drops 0)\n",
      "2018-04-02 19:35:31,815 : INFO : min_count=1 leaves 865142 word corpus (100% of original 865142, drops 0)\n",
      "2018-04-02 19:35:31,950 : INFO : deleting the raw counts dictionary of 27603 items\n",
      "2018-04-02 19:35:31,951 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2018-04-02 19:35:31,952 : INFO : downsampling leaves estimated 651839 word corpus (75.3% of prior 865142)\n",
      "2018-04-02 19:35:32,022 : INFO : estimated required memory for 27603 words and 300 dimensions: 80048700 bytes\n",
      "2018-04-02 19:35:32,023 : INFO : resetting layer weights\n",
      "2018-04-02 19:35:32,694 : INFO : training model with 4 workers on 27603 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-04-02 19:35:33,392 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 19:35:33,402 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 19:35:33,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 19:35:33,410 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 19:35:33,410 : INFO : EPOCH - 1 : training on 865142 raw words (651881 effective words) took 0.7s, 932059 effective words/s\n",
      "2018-04-02 19:35:34,099 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 19:35:34,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 19:35:34,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 19:35:34,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 19:35:34,115 : INFO : EPOCH - 2 : training on 865142 raw words (652219 effective words) took 0.7s, 936640 effective words/s\n",
      "2018-04-02 19:35:34,865 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 19:35:34,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 19:35:34,878 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 19:35:34,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 19:35:34,882 : INFO : EPOCH - 3 : training on 865142 raw words (652133 effective words) took 0.7s, 874432 effective words/s\n",
      "2018-04-02 19:35:35,683 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 19:35:35,694 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 19:35:35,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 19:35:35,702 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 19:35:35,702 : INFO : EPOCH - 4 : training on 865142 raw words (652268 effective words) took 0.8s, 816931 effective words/s\n",
      "2018-04-02 19:35:36,388 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 19:35:36,398 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 19:35:36,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 19:35:36,405 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 19:35:36,406 : INFO : EPOCH - 5 : training on 865142 raw words (652375 effective words) took 0.7s, 941746 effective words/s\n",
      "2018-04-02 19:35:36,406 : INFO : training on a 4325710 raw words (3260876 effective words) took 3.7s, 878679 effective words/s\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = gensim.models.Word2Vec(tokenized_sentences, min_count=1, size=300, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec_model = gensim.models.Word2Vec(min_count=1, size=500, workers=4, iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-23 02:50:25,421 : INFO : storing 27603x300 projection weights into /home/ubuntu/Thesis/new_classification\n"
     ]
    }
   ],
   "source": [
    "# word2vec_model.wv.save_word2vec_format('/home/ubuntu/Thesis/new_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec_model.wv.load_word2vec_format('/home/ubuntu/Thesis/classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer_keras = Tokenizer()\n",
    "\n",
    "tokenizer_keras.fit_on_texts(pandas_entire['sentences'])\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences_keras = tokenizer_keras.texts_to_sequences(pandas_entire['sentences'])\n",
    "\n",
    "padded_seq_keras = pad_sequences(sequences_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_seq_shape (80920, 51)\n"
     ]
    }
   ],
   "source": [
    "print('padded_seq_shape', padded_seq_keras.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_model.wv['listen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "x = padded_seq_keras\n",
    "y = pandas_entire['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80920,) (80920, 51)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "word_index = tokenizer_keras.word_index\n",
    "\n",
    "\n",
    "vocab_size = len(word_index)\n",
    "print(vocab_size)\n",
    "\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embedding_matrix = np.zeros((vocab_size+1, embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for word,i in word_index.items():\n",
    "    if word in word2vec_model:\n",
    "        embedding_vector = word2vec_model[word]\n",
    "    else:\n",
    "        embedding_vector = None\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the CNN model to classify texts. Its bidirectional model. Super cool results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling1D, MaxPooling2D, UpSampling1D, Dropout, Cropping2D, Conv1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import Embedding, Dense, Flatten\n",
    "from keras.layers import Merge\n",
    "from keras.layers import LSTM, Bidirectional, Conv1D, concatenate, Permute, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_length_variable = padded_seq_keras.shape[1]\n",
    "seed = 0\n",
    "\n",
    "import pdb\n",
    "\n",
    "convs = []\n",
    "filter_sizes = [2,3]\n",
    "\n",
    "\n",
    "def create_cnn(include_top = True, weights= None):\n",
    "    \n",
    "    sequence_input = Input(shape=(input_length_variable, ), dtype='int32', name='input')\n",
    "    embedding_layer = Embedding(vocab_size + 1, embedding_size, weights= [embedding_matrix],\n",
    "                                input_length= input_length_variable,\n",
    "                                name = 'embedding', trainable=True)(sequence_input)\n",
    "    pdb.set_trace()\n",
    "    print(embedding_layer.shape)\n",
    "    print(sequence_input.shape)\n",
    "    \n",
    "    \n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv1D(nb_filter=2,filter_length=fsz,activation='relu')(embedding_layer)\n",
    "        lstm = Bidirectional(LSTM(1, return_sequences = True))(l_conv)\n",
    "        l_pool = GlobalMaxPooling1D()(lstm)\n",
    "#         lstm = (LSTM(256))(l_pool)\n",
    "        convs.append(l_pool)\n",
    "        \n",
    "#     nn = Concatenate(name='features')(convs)\n",
    "    l_merge = Merge(mode='concat', concat_axis=1)(convs)\n",
    "#     l_cov1= Conv1D(128, 5, activation='relu')(l_merge)\n",
    "#     l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "#     l_cov2 = Conv1D(256, 5, activation='relu')(l_pool1)\n",
    "#     l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "#     l_flat = Flatten()(l_pool2)\n",
    "#     l_dense = Dense(128, activation='relu')(l_flat)\n",
    "    \n",
    "    if include_top:\n",
    "        nn = Dropout(0.5, seed=seed, name='dropout')(l_merge)\n",
    "        weights_np = Dense(nn)\n",
    "        weights_np = weights_np.get_weights()\n",
    "        predictions = Dense(1, init='normal', name='output')(nn)\n",
    "        model = Model(sequence_input, predictions)\n",
    "    else:\n",
    "        model = Model(sequence_input, nn)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-52-e6cc26e33dca>(17)create_cnn()\n",
      "-> print(embedding_layer.shape)\n",
      "(Pdb) n\n",
      "(?, 51, 300)\n",
      "> <ipython-input-52-e6cc26e33dca>(18)create_cnn()\n",
      "-> print(sequence_input.shape)\n",
      "(Pdb) c\n",
      "(?, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=2, kernel_size=2)`\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=2, kernel_size=3)`\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, name=\"output\", kernel_initializer=\"normal\")`\n"
     ]
    }
   ],
   "source": [
    "keras_model = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 51, 300)      6839100     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 50, 2)        1202        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 49, 2)        1802        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 50, 2)        32          conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 49, 2)        32          conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 2)            0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 2)            0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_9 (Merge)                 (None, 4)            0           global_max_pooling1d_20[0][0]    \n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4)            0           merge_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            5           dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,842,173\n",
      "Trainable params: 6,842,173\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_splits = 3\n",
    "\n",
    "kf = KFold(n_splits=n_splits)\n",
    "kf.get_n_splits(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 99.5% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53946, 51) (53946,)\n",
      "Train on 53946 samples, validate on 26974 samples\n",
      "Epoch 1/5\n",
      "53946/53946 [==============================] - 207s 4ms/step - loss: 0.1161 - mean_absolute_error: 0.2177 - acc: 0.8529 - val_loss: 0.1349 - val_mean_absolute_error: 0.3347 - val_acc: 0.8840\n",
      "Epoch 2/5\n",
      "53946/53946 [==============================] - 206s 4ms/step - loss: 0.0546 - mean_absolute_error: 0.1576 - acc: 0.9331 - val_loss: 0.0807 - val_mean_absolute_error: 0.2424 - val_acc: 0.9209\n",
      "Epoch 3/5\n",
      "53946/53946 [==============================] - 206s 4ms/step - loss: 0.0483 - mean_absolute_error: 0.1492 - acc: 0.9446 - val_loss: 0.0768 - val_mean_absolute_error: 0.2394 - val_acc: 0.9299\n",
      "Epoch 4/5\n",
      "53946/53946 [==============================] - 202s 4ms/step - loss: 0.0455 - mean_absolute_error: 0.1453 - acc: 0.9479 - val_loss: 0.0756 - val_mean_absolute_error: 0.2383 - val_acc: 0.9356\n",
      "Epoch 5/5\n",
      "53946/53946 [==============================] - 195s 4ms/step - loss: 0.0457 - mean_absolute_error: 0.1458 - acc: 0.9476 - val_loss: 0.0678 - val_mean_absolute_error: 0.2274 - val_acc: 0.9444\n",
      "(53947, 51) (53947,)\n",
      "Train on 53947 samples, validate on 26973 samples\n",
      "Epoch 1/5\n",
      "53947/53947 [==============================] - 194s 4ms/step - loss: 0.0741 - mean_absolute_error: 0.2179 - acc: 0.9438 - val_loss: 0.0165 - val_mean_absolute_error: 0.1191 - val_acc: 0.9974\n",
      "Epoch 2/5\n",
      "53947/53947 [==============================] - 194s 4ms/step - loss: 0.0686 - mean_absolute_error: 0.2164 - acc: 0.9586 - val_loss: 0.0177 - val_mean_absolute_error: 0.1261 - val_acc: 0.9976\n",
      "Epoch 3/5\n",
      "53947/53947 [==============================] - 195s 4ms/step - loss: 0.0669 - mean_absolute_error: 0.2142 - acc: 0.9617 - val_loss: 0.0166 - val_mean_absolute_error: 0.1219 - val_acc: 0.9980\n",
      "Epoch 4/5\n",
      "53947/53947 [==============================] - 194s 4ms/step - loss: 0.0670 - mean_absolute_error: 0.2149 - acc: 0.9622 - val_loss: 0.0183 - val_mean_absolute_error: 0.1277 - val_acc: 0.9972\n",
      "Epoch 5/5\n",
      "53947/53947 [==============================] - 194s 4ms/step - loss: 0.0662 - mean_absolute_error: 0.2146 - acc: 0.9638 - val_loss: 0.0191 - val_mean_absolute_error: 0.1315 - val_acc: 0.9969\n",
      "(53947, 51) (53947,)\n",
      "Train on 53947 samples, validate on 26973 samples\n",
      "Epoch 1/5\n",
      "53947/53947 [==============================] - 195s 4ms/step - loss: 0.0631 - mean_absolute_error: 0.2036 - acc: 0.9368 - val_loss: 0.0597 - val_mean_absolute_error: 0.2418 - val_acc: 0.9947\n",
      "Epoch 2/5\n",
      "53947/53947 [==============================] - 194s 4ms/step - loss: 0.0601 - mean_absolute_error: 0.1938 - acc: 0.9352 - val_loss: 0.0554 - val_mean_absolute_error: 0.2326 - val_acc: 0.9950\n",
      "Epoch 3/5\n",
      "53947/53947 [==============================] - 194s 4ms/step - loss: 0.0601 - mean_absolute_error: 0.1938 - acc: 0.9347 - val_loss: 0.0641 - val_mean_absolute_error: 0.2497 - val_acc: 0.9930\n",
      "Epoch 4/5\n",
      "53947/53947 [==============================] - 194s 4ms/step - loss: 0.0596 - mean_absolute_error: 0.1934 - acc: 0.9363 - val_loss: 0.0593 - val_mean_absolute_error: 0.2406 - val_acc: 0.9940\n",
      "Epoch 5/5\n",
      "53947/53947 [==============================] - 193s 4ms/step - loss: 0.0595 - mean_absolute_error: 0.1929 - acc: 0.9361 - val_loss: 0.0524 - val_mean_absolute_error: 0.2261 - val_acc: 0.9950\n"
     ]
    }
   ],
   "source": [
    "# train cnn\n",
    "keras_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'acc'])\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "for train_index, val_index in kf.split(x):\n",
    "    x_train, x_val = x[train_index], x[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    print(x_train.shape, y_train.shape)\n",
    "    keras_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_1 = keras_model.save_weights('/home/ubuntu/Thesis/new_classification.h5')\n",
    "# model_1_1 = keras_model.save('/home/ubuntu/Thesis/new_classification_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # train cnn\n",
    "# def mean_pred(y_true, y_pred):\n",
    "#     return K.mean(y_pred)\n",
    "\n",
    "# keras_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', mean_pred])\n",
    "\n",
    "# batch_size = 128\n",
    "# epochs = 1\n",
    "# for train_index, val_index in kf.split(x):\n",
    "#     x_train, x_val = x[train_index], x[val_index]\n",
    "#     y_train, y_val = y[train_index], y[val_index]\n",
    "#     print(x_train.shape, y_train.shape)\n",
    "#     keras_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_2 = keras_model.save_weights('/home/ubuntu/Thesis/new_classification_second.h5')\n",
    "# model_2_1 = keras_model.save('/home/ubuntu/Thesis/new_classification_second_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check = ['so you’d like it who’s bigger ideas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "text = pandas_entire['sentences'].astype(str).tolist()\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences_check = tokenizer.texts_to_sequences(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = pad_sequences(sequences_check, maxlen=51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_one = load_model('/home/ubuntu/Thesis/new_classification_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = model_one.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92933923]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
